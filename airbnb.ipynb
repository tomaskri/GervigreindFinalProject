{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We fetch the data**\n",
    "\n",
    "We select one city to start with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2978, 10)"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "data = pd.read_csv('listings_stockholm.csv.gz', nrows=13815, compression='gzip')\n",
    "\n",
    "data = data[['accommodates','bedrooms', 'beds', 'review_scores_rating','review_scores_location','review_scores_value','reviews_per_month','property_type','room_type','price']]\n",
    "# data = data[['accommodates','bedrooms','price']]\n",
    "data = data.dropna()\n",
    "data.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We define a function to change string features to an integer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_features_to_num(array):\n",
    "    dictOfWords = { i : np.unique(array)[i] for i in range(0, len(np.unique(array)) ) }\n",
    "    dictOfWords = {v: k for k, v in dictOfWords.items()}\n",
    "    \n",
    "    values = np.zeros(len(array))\n",
    "    for i in range(len(array)):\n",
    "        values[i] = dictOfWords.get(array[i])\n",
    "        \n",
    "    return values, dictOfWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectPropertyType(type, X, y):\n",
    "    xlist = []\n",
    "    ylist = []\n",
    "    for i in range(X.shape[0]):\n",
    "        if(X[i,-2] == type):\n",
    "            xlist.append(X[i,:])\n",
    "            ylist.append(y[i])\n",
    "    return np.array(xlist), np.array(ylist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data split into features and target**\n",
    "\n",
    "We also change the target from a string to a float. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Boat': 0, 'Entire bungalow': 1, 'Entire cabin': 2, 'Entire condo': 3, 'Entire cottage': 4, 'Entire guest suite': 5, 'Entire guesthouse': 6, 'Entire home': 7, 'Entire in-law': 8, 'Entire loft': 9, 'Entire place': 10, 'Entire rental unit': 11, 'Entire serviced apartment': 12, 'Entire townhouse': 13, 'Entire vacation home': 14, 'Entire villa': 15, 'Private room': 16, 'Private room in bed and breakfast': 17, 'Private room in boat': 18, 'Private room in casa particular': 19, 'Private room in condo': 20, 'Private room in guest suite': 21, 'Private room in guesthouse': 22, 'Private room in home': 23, 'Private room in hostel': 24, 'Private room in houseboat': 25, 'Private room in loft': 26, 'Private room in rental unit': 27, 'Private room in serviced apartment': 28, 'Private room in townhouse': 29, 'Private room in vacation home': 30, 'Private room in villa': 31, 'Room in aparthotel': 32, 'Room in bed and breakfast': 33, 'Room in boutique hotel': 34, 'Room in hostel': 35, 'Room in hotel': 36, 'Room in serviced apartment': 37, 'Shared room in bed and breakfast': 38, 'Shared room in casa particular': 39, 'Shared room in condo': 40, 'Shared room in guesthouse': 41, 'Shared room in home': 42, 'Shared room in hostel': 43, 'Shared room in rental unit': 44, 'Shared room in villa': 45, 'Tiny home': 46}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1257, 9)"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "datanp = np.array(data)\n",
    "X = datanp[:,:-1]\n",
    "y = datanp[:,-1]\n",
    "\n",
    "for i in range(len(y)):\n",
    "    y[i] = float(re.sub(\",\", \"\", (y[i][1:])))\n",
    "\n",
    "X[:, -2], propertytype_dict = string_features_to_num(X[:, -2])\n",
    "X[:, -1], roomtype_dict = string_features_to_num(X[:, -1])\n",
    "\n",
    "print(propertytype_dict)\n",
    "\n",
    "X, y = selectPropertyType(propertytype_dict.get('Entire rental unit'), X, y)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data split into train/val/test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Models imported**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "linear_model = LinearRegression()\n",
    "svr_model = SVR(C=60, epsilon=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Models fit and scored**\n",
    "\n",
    "We fit the models on the training set and test with the linear regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22664130585871223 0.3447304867719526 0.1762739709421579\n"
     ]
    }
   ],
   "source": [
    "linear_model.fit(X_train, y_train)\n",
    "linear_train_score = linear_model.score(X_train, y_train)\n",
    "linear_val_score = linear_model.score(X_val,y_val)\n",
    "linear_test_score = linear_model.score(X_test,y_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(linear_train_score, linear_test_score, linear_val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39450347059020363\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import NuSVR\n",
    "\n",
    "svr_model = NuSVR(C=600, nu=0.3)\n",
    "svr_model.fit(X_train, y_train)\n",
    "svr_test_score = svr_model.score(X_test, y_test)\n",
    "print(svr_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15974789256444166\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "regr = RandomForestRegressor(max_depth=6, random_state=0, n_estimators=100)\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "print(regr.score(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3463538067194464\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "clf = Ridge(alpha=5)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# import pandas as pd\n",
    "# import tensorflow as tf\n",
    "# import matplotlib.pyplot as plt\n",
    "# from tensorflow.keras import Model\n",
    "# from tensorflow.keras import Sequential\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from tensorflow.keras.layers import Dense, Dropout\n",
    "# from tensorflow.keras.losses import MeanSquaredLogarithmicError\n",
    "# from sklearn.metrics import r2_score\n",
    "\n",
    "# X_train = pd.DataFrame(X_train)\n",
    "# X_test = pd.DataFrame(X_test)\n",
    "# y_train = pd.DataFrame(y_train)\n",
    "# y_test = pd.DataFrame(y_test)\n",
    "\n",
    "# def scale_datasets(x_train, x_test):\n",
    "#     \"\"\"\n",
    "#     Standard Scale test and train data\n",
    "#     Z - Score normalization\n",
    "#     \"\"\"\n",
    "#     standard_scaler = StandardScaler()\n",
    "#     x_train_scaled = pd.DataFrame(\n",
    "#         standard_scaler.fit_transform(x_train),\n",
    "#         columns=x_train.columns\n",
    "#     )\n",
    "#     x_test_scaled = pd.DataFrame(\n",
    "#         standard_scaler.transform(x_test),\n",
    "#         columns = x_test.columns\n",
    "#     )\n",
    "#     return x_train_scaled, x_test_scaled\n",
    "# x_train_scaled, x_test_scaled = scale_datasets(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden_units1 = 160\n",
    "# hidden_units2 = 480\n",
    "# hidden_units3 = 256\n",
    "# learning_rate = 5e-2\n",
    "# # Creating model using the Sequential in tensorflow\n",
    "# def build_model_using_sequential():\n",
    "#   model = Sequential([\n",
    "#     Dense(hidden_units1, kernel_initializer='normal', activation='relu'),\n",
    "#     Dropout(0.2),\n",
    "#     Dense(hidden_units2, kernel_initializer='normal', activation='relu'),\n",
    "#     Dropout(0.2),\n",
    "#     Dense(hidden_units3, kernel_initializer='normal', activation='relu'),\n",
    "#     Dense(1, kernel_initializer='normal', activation='linear')\n",
    "#   ])\n",
    "#   return model\n",
    "# # build the model\n",
    "# model = build_model_using_sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # loss function\n",
    "# msle = MeanSquaredLogarithmicError()\n",
    "# model.compile(\n",
    "#     loss=msle, \n",
    "#     optimizer=Adam(learning_rate=learning_rate), \n",
    "#     metrics=[msle]\n",
    "# )\n",
    "# # train the model\n",
    "# history = model.fit(\n",
    "#     x_train_scaled.values, \n",
    "#     np.asarray(y_train.values).astype('float32'), \n",
    "#     epochs=10, \n",
    "#     batch_size=10,\n",
    "#     validation_split=0.2\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_history(history, key):\n",
    "#   plt.plot(history.history[key])\n",
    "#   plt.plot(history.history['val_'+key])\n",
    "#   plt.xlabel(\"Epochs\")\n",
    "#   plt.ylabel(key)\n",
    "#   plt.legend([key, 'val_'+key])\n",
    "#   plt.show()\n",
    "# # Plot the history\n",
    "# plot_history(history, 'mean_squared_logarithmic_error')\n",
    "\n",
    "# X_test['prediction'] = model.predict(x_test_scaled)\n",
    "\n",
    "# r2_score(y_test, model.predict(x_test_scaled))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a1beba0eec8c8900e76e1a0c55ed52e22896ea47aa24a217547588df6ec7114"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
